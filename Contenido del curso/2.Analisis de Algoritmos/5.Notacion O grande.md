# Big O

Normalmente cuando hacemos un análisis de un algoritmo, solemos usar la notación de landau también conocida como o grande y o pequeña, aunque ahora nos fijamos solo en la O grande, y en general en todos los lados será referenciada por big O.

La notación de big O simplemente nos indica que si tras hacer un análisis resulta que tenemos que hacer 10n² + nlogn operaciones, esa función tiene un orden de n², es decir que el elemento que más crece de esa función es n², la notación de O grande discrimina las constantes y otros posibles factores del coste, no te da información en detalle, sino que simplemente te da la indicación de que ese algoritmo crece a un ritmo de N².

A veces verás cosas como que haces un análisis y te da N² + NLogN, si crees que el coste seria O(N²+NLogN) estas equivocado, como te decía las constantes se borran por que lo que importa es qué tan rápido crezca una función y una constante no ayuda mucho luego si por ejemplo tuviéramos N²+N² donde N² crece bastante más rápido que NLogN, entonces aquí tendriamos 2N², y como te decía antes si quitamos las constantes entonces en este caso NLogN, también es una constante se quita, y solo se mantiene el factor que más crece sin otras constantes en este caso N²

Para que lo entendáis bien veamos la siguiente gráfica:

![](https://dc722jrlp2zu8.cloudfront.net/media/uploads/2019/10/02/graf1.png)

En esta gráfica podéis ver la función en azul xlogx, y en rojo 1000logx, como os dije antes es posible que al principio debido a la constante que esta multiplicando pueda parecer que ahora logx crece bastante más deprisa que xlogx, pero esto solo sera por un tiempo concreto, si nos vamos alejando de la gráfica veremos que a partir de un punto concreto se ve parecido a que si no hubiéramos multiplicado logx:

![](https://dc722jrlp2zu8.cloudfront.net/media/uploads/2019/10/02/graf2.png)

Si subimos hasta y = 10000, vemos que la función tiene el mismo coste que xlogx, y si subimos a 100000

![](https://dc722jrlp2zu8.cloudfront.net/media/uploads/2019/10/02/graf3.png)

De poco se diferencia a la gráfica donde logx no está siendo multiplicada por nada

![](https://dc722jrlp2zu8.cloudfront.net/media/uploads/2019/10/02/graf4.png)

Y aquí es donde tendrías que ver por ejemplo cuál será el tamaño de vuestra entrada por que si por ejemplo vuestro algoritmo solo va a procesar como mucho 100 elementos pues nos será mejor usar el algoritmo xlogx que 1000logx

Como podéis ver aquí por mucho que suméis algo extremadamente grande a la función LogN, como para que los primeros mil elementos dan como resultado algo parecido o incluso superior a NLogN, a la larga dará igual, todo esto es parte de una teoría bastante más compleja donde hay que recordar algunas de las cosas de matemáticas como limites y asíntotas entre otros.

Por lo que solo tenéis que tener claro que os tenéis que quedar con el factor que más crezca sin constantes y eso será el orden o la complejidad de vuestro algoritmo.

En general siempre te vas a encontrar con los siguientes órdenes:

![](https://dc722jrlp2zu8.cloudfront.net/media/uploads/2019/10/02/graf5.png)

y esta es la forma en la que crecen

Lo ideal de cualquier algoritmo sería conseguir siempre O(1) dado que esto básicamente significa que da igual el tamaño de la entrada la función siempre tardará lo mismo

Otra cosa que hay que tener en cuenta es que hay diferentes análisis, uno para el caso mejor, otro para el caso promedio, otro para el caso peor, otro para el caso amortizado, y todo esto entraría dentro de un análisis que tendríais que hacer a la hora de ver que estructura de datos necesitarías, en general nos fijaremos en el caso peor.
